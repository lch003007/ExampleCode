"""
ai_service_example.py - AI Service ä½¿ç”¨ç¯„ä¾‹
å±•ç¤ºå¦‚ä½•ä½¿ç”¨ AI Service çš„å„ç¨®åŠŸèƒ½
"""

import asyncio
import sys
import os

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.shared.services.ai import ai_service, PromptTemplates


async def example_basic_chat():
    """ç¯„ä¾‹ 1: åŸºç¤å°è©±"""
    print("=" * 60)
    print("ç¯„ä¾‹ 1: åŸºç¤å°è©±")
    print("=" * 60)
    
    response = await ai_service.chat(
        message="è«‹ç”¨ä¸€å¥è©±ä»‹ç´¹ FastAPI",
        model="gpt-3.5-turbo"
    )
    
    print(f"å•é¡Œ: è«‹ç”¨ä¸€å¥è©±ä»‹ç´¹ FastAPI")
    print(f"å›ç­”: {response.message}")
    print(f"æ¨¡å‹: {response.model}")
    print()


async def example_with_system_prompt():
    """ç¯„ä¾‹ 2: ä½¿ç”¨ç³»çµ±æç¤ºè©"""
    print("=" * 60)
    print("ç¯„ä¾‹ 2: ä½¿ç”¨ç³»çµ±æç¤ºè©")
    print("=" * 60)
    
    response = await ai_service.chat(
        message="å¯«ä¸€å€‹ Hello World ç¨‹å¼",
        model="gpt-3.5-turbo",
        system_prompt="ä½ æ˜¯ä¸€å€‹ Python å°ˆå®¶ï¼Œè«‹ç”¨ç°¡æ½”çš„ç¨‹å¼ç¢¼å›ç­”ã€‚"
    )
    
    print(f"å•é¡Œ: å¯«ä¸€å€‹ Hello World ç¨‹å¼")
    print(f"å›ç­”:\n{response.message}")
    print()


async def example_with_template():
    """ç¯„ä¾‹ 3: ä½¿ç”¨é è¨­æ¨¡æ¿"""
    print("=" * 60)
    print("ç¯„ä¾‹ 3: ä½¿ç”¨é è¨­æ¨¡æ¿")
    print("=" * 60)
    
    # ä½¿ç”¨ç¨‹å¼è¨­è¨ˆåŠ©æ‰‹æ¨¡æ¿
    response = await ai_service.chat_with_template(
        message="å¯¦ç¾ä¸€å€‹ Fibonacci æ•¸åˆ—å‡½æ•¸",
        template_name="programming",
        model="gpt-3.5-turbo"
    )
    
    print(f"å•é¡Œ: å¯¦ç¾ä¸€å€‹ Fibonacci æ•¸åˆ—å‡½æ•¸")
    print(f"å›ç­”:\n{response.message}")
    print()


async def example_conversation():
    """ç¯„ä¾‹ 4: å¤šè¼ªå°è©±"""
    print("=" * 60)
    print("ç¯„ä¾‹ 4: å¤šè¼ªå°è©±")
    print("=" * 60)
    
    # å‰µå»ºå°è©±
    conversation_id = ai_service.create_conversation()
    print(f"å‰µå»ºå°è©± ID: {conversation_id}\n")
    
    # ç¬¬ä¸€è¼ªå°è©±
    response1 = await ai_service.chat(
        message="æˆ‘æƒ³å­¸ç¿’ Python çš„è£é£¾å™¨",
        conversation_id=conversation_id,
        model="gpt-3.5-turbo"
    )
    print(f"ç”¨æˆ¶: æˆ‘æƒ³å­¸ç¿’ Python çš„è£é£¾å™¨")
    print(f"AI: {response1.message[:200]}...\n")
    
    # ç¬¬äºŒè¼ªå°è©±ï¼ˆAI æœƒè¨˜ä½å‰é¢çš„å…§å®¹ï¼‰
    response2 = await ai_service.chat(
        message="å¯ä»¥çµ¦æˆ‘ä¸€å€‹å¯¦éš›çš„ä¾‹å­å—ï¼Ÿ",
        conversation_id=conversation_id,
        model="gpt-3.5-turbo"
    )
    print(f"ç”¨æˆ¶: å¯ä»¥çµ¦æˆ‘ä¸€å€‹å¯¦éš›çš„ä¾‹å­å—ï¼Ÿ")
    print(f"AI: {response2.message[:200]}...\n")
    
    # æŸ¥çœ‹å°è©±æ­·å²
    history = ai_service.get_conversation(conversation_id)
    print(f"å°è©±æ­·å²å…±æœ‰ {len(history.messages)} æ¢è¨Šæ¯")
    
    # æ¸…é™¤å°è©±
    ai_service.delete_conversation(conversation_id)
    print(f"å·²åˆªé™¤å°è©±\n")


async def example_streaming():
    """ç¯„ä¾‹ 5: ä¸²æµè¼¸å‡º"""
    print("=" * 60)
    print("ç¯„ä¾‹ 5: ä¸²æµè¼¸å‡º")
    print("=" * 60)
    
    print("å•é¡Œ: ä»‹ç´¹ä¸€ä¸‹ DDD æ¶æ§‹")
    print("å›ç­”: ", end="", flush=True)
    
    async for chunk in ai_service.stream_chat(
        message="ç”¨ 3 å¥è©±ä»‹ç´¹ DDDï¼ˆé ˜åŸŸé©…å‹•è¨­è¨ˆï¼‰æ¶æ§‹",
        model="gpt-3.5-turbo",
        system_prompt="è«‹ç”¨ç°¡æ½”çš„èªè¨€å›ç­”"
    ):
        if not chunk.is_final:
            print(chunk.content, end="", flush=True)
        else:
            print("\n[å®Œæˆ]\n")


async def example_summarize():
    """ç¯„ä¾‹ 6: æ–‡å­—æ‘˜è¦"""
    print("=" * 60)
    print("ç¯„ä¾‹ 6: æ–‡å­—æ‘˜è¦")
    print("=" * 60)
    
    long_text = """
    FastAPI æ˜¯ä¸€å€‹ç¾ä»£ã€å¿«é€Ÿï¼ˆé«˜æ€§èƒ½ï¼‰çš„ Web æ¡†æ¶ï¼Œç”¨æ–¼åŸºæ–¼æ¨™æº– Python é¡å‹æç¤ºä½¿ç”¨ Python 3.7+ æ§‹å»º APIã€‚
    FastAPI çš„é—œéµç‰¹æ€§åŒ…æ‹¬ï¼šå¿«é€Ÿï¼šèˆ‡ NodeJS å’Œ Go ç›¸ç•¶çš„éå¸¸é«˜çš„æ€§èƒ½ï¼ˆæ„Ÿè¬ Starlette å’Œ Pydanticï¼‰ã€‚
    æœ€å¿«çš„ Python æ¡†æ¶ä¹‹ä¸€ã€‚å¿«é€Ÿç·¨ç¢¼ï¼šå°‡åŠŸèƒ½é–‹ç™¼é€Ÿåº¦æé«˜ç´„ 200% è‡³ 300%ã€‚
    æ›´å°‘çš„éŒ¯èª¤ï¼šæ¸›å°‘ç´„ 40% çš„äººç‚ºï¼ˆé–‹ç™¼äººå“¡ï¼‰å¼•èµ·çš„éŒ¯èª¤ã€‚
    ç›´è§€ï¼šå‡ºè‰²çš„ç·¨è¼¯å™¨æ”¯æŒã€‚åˆ°è™•éƒ½å¯ä»¥è‡ªå‹•å®Œæˆã€‚æ¸›å°‘èª¿è©¦æ™‚é–“ã€‚
    ç°¡å–®ï¼šæ—¨åœ¨æ˜“æ–¼ä½¿ç”¨å’Œå­¸ç¿’ã€‚æ¸›å°‘é–±è®€æ–‡æª”çš„æ™‚é–“ã€‚
    ç°¡çŸ­ï¼šæœ€å°åŒ–ä»£ç¢¼é‡è¤‡ã€‚æ¯å€‹åƒæ•¸è²æ˜çš„å¤šå€‹åŠŸèƒ½ã€‚æ›´å°‘çš„éŒ¯èª¤ã€‚
    å¥å£¯ï¼šç²å–ç”Ÿç”¢å°±ç·’çš„ä»£ç¢¼ã€‚å…·æœ‰è‡ªå‹•äº¤äº’å¼æ–‡æª”ã€‚
    åŸºæ–¼æ¨™æº–ï¼šåŸºæ–¼ï¼ˆä¸¦å®Œå…¨å…¼å®¹ï¼‰API çš„é–‹æ”¾æ¨™æº–ï¼šOpenAPIï¼ˆä»¥å‰ç¨±ç‚º Swaggerï¼‰å’Œ JSON Schemaã€‚
    """
    
    summary = await ai_service.summarize_text(
        text=long_text,
        max_length=100,
        model="gpt-3.5-turbo"
    )
    
    print(f"åŸæ–‡é•·åº¦: {len(long_text)} å­—")
    print(f"æ‘˜è¦: {summary}")
    print()


async def example_translate():
    """ç¯„ä¾‹ 7: æ–‡å­—ç¿»è­¯"""
    print("=" * 60)
    print("ç¯„ä¾‹ 7: æ–‡å­—ç¿»è­¯")
    print("=" * 60)
    
    # è‹±ç¿»ä¸­
    translation = await ai_service.translate_text(
        text="Hello, how are you today?",
        target_language="ç¹é«”ä¸­æ–‡",
        model="gpt-3.5-turbo"
    )
    
    print(f"åŸæ–‡: Hello, how are you today?")
    print(f"ç¿»è­¯: {translation}")
    print()


async def example_generate_code():
    """ç¯„ä¾‹ 8: ç¨‹å¼ç¢¼ç”Ÿæˆ"""
    print("=" * 60)
    print("ç¯„ä¾‹ 8: ç¨‹å¼ç¢¼ç”Ÿæˆ")
    print("=" * 60)
    
    code = await ai_service.generate_code(
        description="å¯¦ç¾ä¸€å€‹è¨ˆç®—éšä¹˜çš„éè¿´å‡½æ•¸",
        language="Python",
        model="gpt-3.5-turbo"
    )
    
    print(f"éœ€æ±‚: å¯¦ç¾ä¸€å€‹è¨ˆç®—éšä¹˜çš„éè¿´å‡½æ•¸")
    print(f"ç”Ÿæˆçš„ç¨‹å¼ç¢¼:\n{code}")
    print()


async def example_extract_json():
    """ç¯„ä¾‹ 9: JSON æå–"""
    print("=" * 60)
    print("ç¯„ä¾‹ 9: JSON æå–")
    print("=" * 60)
    
    text = "å¼µä¸‰ï¼Œ35 æ­²ï¼Œä½åœ¨å°åŒ—å¸‚å¤§å®‰å€ï¼Œè·æ¥­æ˜¯è»Ÿé«”å·¥ç¨‹å¸«ï¼Œèˆˆè¶£æ˜¯é–±è®€å’Œæ—…éŠ"
    
    json_data = await ai_service.extract_json(
        text=text,
        schema_description="""
        è«‹æŒ‰ç…§ä»¥ä¸‹æ ¼å¼æå–è³‡è¨Šï¼š
        {
            "name": "å§“å",
            "age": å¹´é½¡ï¼ˆæ•¸å­—ï¼‰,
            "address": "åœ°å€",
            "occupation": "è·æ¥­",
            "hobbies": ["èˆˆè¶£åˆ—è¡¨"]
        }
        """,
        model="gpt-3.5-turbo"
    )
    
    print(f"åŸæ–‡: {text}")
    print(f"æå–çš„ JSON:\n{json_data}")
    print()


async def example_list_resources():
    """ç¯„ä¾‹ 10: åˆ—å‡ºå¯ç”¨è³‡æº"""
    print("=" * 60)
    print("ç¯„ä¾‹ 10: åˆ—å‡ºå¯ç”¨è³‡æº")
    print("=" * 60)
    
    # åˆ—å‡ºå¯ç”¨æ¨¡å‹
    models = ai_service.get_available_models()
    print("å¯ç”¨çš„ AI æ¨¡å‹:")
    for model in models:
        print(f"  - {model}")
    print()
    
    # åˆ—å‡ºå¯ç”¨æ¨¡æ¿
    templates = ai_service.get_available_templates()
    print("å¯ç”¨çš„æç¤ºè©æ¨¡æ¿:")
    for name, prompt in templates.items():
        print(f"  - {name}: {prompt[:60]}...")
    print()


async def main():
    """ä¸»å‡½æ•¸ï¼šé‹è¡Œæ‰€æœ‰ç¯„ä¾‹"""
    print("\nğŸ¤– AI Service ä½¿ç”¨ç¯„ä¾‹\n")
    
    # æª¢æŸ¥ API Key
    from src.core.config import settings
    if not settings.ai.openai_api_key:
        print("âŒ éŒ¯èª¤: æœªè¨­å®š OPENAI_API_KEY")
        print("è«‹åœ¨ .env æ–‡ä»¶ä¸­è¨­å®š: OPENAI_API_KEY=your-api-key")
        return
    
    print("âœ… å·²æª¢æ¸¬åˆ° OpenAI API Key\n")
    
    try:
        # é‹è¡Œå„å€‹ç¯„ä¾‹
        await example_basic_chat()
        await example_with_system_prompt()
        await example_with_template()
        await example_conversation()
        await example_streaming()
        await example_summarize()
        await example_translate()
        await example_generate_code()
        await example_extract_json()
        await example_list_resources()
        
        print("=" * 60)
        print("âœ… æ‰€æœ‰ç¯„ä¾‹é‹è¡Œå®Œæˆï¼")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ éŒ¯èª¤: {str(e)}")
        print("è«‹ç¢ºèª:")
        print("1. OpenAI API Key æ˜¯å¦æ­£ç¢º")
        print("2. ç¶²è·¯é€£æ¥æ˜¯å¦æ­£å¸¸")
        print("3. API é…é¡æ˜¯å¦å……è¶³")


if __name__ == "__main__":
    # é‹è¡Œç¯„ä¾‹
    asyncio.run(main())

